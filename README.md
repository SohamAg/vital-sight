# ğŸš¨ VitalSight

**Context-Aware Environment System for Real-Time Emergency Detection**

VitalSight is an intelligent surveillance system that combines cutting-edge computer vision with AI-powered analysis to detect and report emergency situations in real-time. From falls and fires to crowd incidents and medical distress, VitalSight provides immediate, actionable intelligence to save lives.

---

## âœ¨ Key Features

### ğŸ¯ **Multi-Modal Emergency Detection**
- **Fall Detection**: Identifies falls using pose estimation and body orientation analysis
- **Fire Detection**: HSV-based flame and smoke detection with high accuracy
- **Medical Distress**: Detects respiratory distress and severe injuries through pose analysis
- **Crowd Management**: Monitors crowd density and detects violence/panic situations
- **Severe Injury**: Identifies traumatic injuries requiring immediate medical response

### ğŸ¤– **AI-Powered Situation Analysis**
- **Google Gemini 2.0 Flash (Experimental)**: Generates detailed, context-aware incident reports
- **Vision Language Model (VLM)**: Analyzes video frames to provide human-readable situation assessments
- **Priority Classification**: Automatically categorizes incidents (LOW, MEDIUM, HIGH, CRITICAL)
- **Actionable Recommendations**: Each report includes specific response protocols

### ğŸ“º **Modern Web Dashboard**
- **Live CCTV Grid View**: Monitor multiple camera feeds simultaneously with auto-play
- **Real-Time Processing**: Upload videos and watch live as YOLO detection runs frame-by-frame
- **Interactive Reports**: Click any video to view detailed AI-generated incident reports
- **User Authentication**: Secure login system with session management
- **Responsive Design**: Modern, professional UI with Tailwind CSS

### âš¡ **Real-Time Processing Pipeline**
- **YOLO 11 Object Detection**: State-of-the-art object detection with GPU acceleration
- **MediaPipe Pose Estimation**: 17-keypoint body tracking for fall and distress detection
- **Live Video Streaming**: MJPEG streaming shows detection in real-time during processing
- **Async Report Generation**: Gemini reports generated in parallel without blocking video processing
- **Progress Tracking**: Real-time progress bars and frame counters during upload processing

### ğŸ¥ **Multiple Input Modes**
1. **Batch Processing**: Process entire directories of videos automatically
2. **Live Upload**: Upload and process videos through the web interface with live streaming
3. **Webcam Support**: Real-time detection from connected webcams
4. **Video Files**: Support for all major video formats (MP4, AVI, MOV, etc.)

### ğŸ“Š **Intelligent Reporting**
- **Priority-Based Alerts**: Different response protocols for different severity levels
- **Evidence Capture**: Saves the exact frame where the incident was first detected
- **Detailed Context**: Reports include observable details, assessment, and recommended actions
- **Markdown Support**: Rich text formatting for professional report presentation
- **Persistent Storage**: All reports and processed videos saved for review

---

## ğŸ—ï¸ System Architecture

```
VitalSight Architecture
â”œâ”€â”€ ğŸ¥ Input Layer
â”‚   â”œâ”€â”€ Video Files (.mp4, .avi, etc.)
â”‚   â”œâ”€â”€ Webcam Stream (USB, IP cameras)
â”‚   â””â”€â”€ Batch Processing Pipeline
â”‚
â”œâ”€â”€ ğŸ” Detection Engine (detector_v2.py)
â”‚   â”œâ”€â”€ YOLO 11 Object Detection
â”‚   â”œâ”€â”€ MediaPipe Pose Estimation
â”‚   â”œâ”€â”€ Multi-category scoring (fall, fire, distress, injury, violence)
â”‚   â”œâ”€â”€ Temporal debouncing (prevents false alarms)
â”‚   â””â”€â”€ Frame callback for live streaming
â”‚
â”œâ”€â”€ ğŸ¤– AI Analysis Layer (gemini_reporter.py)
â”‚   â”œâ”€â”€ Gemini 2.0 Flash VLM
â”‚   â”œâ”€â”€ Async report generation (threading)
â”‚   â”œâ”€â”€ Priority classification
â”‚   â””â”€â”€ Evidence frame capture
â”‚
â”œâ”€â”€ ğŸŒ Web Application (webapp.py)
â”‚   â”œâ”€â”€ Flask backend with session management
â”‚   â”œâ”€â”€ MJPEG live streaming endpoint
â”‚   â”œâ”€â”€ Video serving & report rendering
â”‚   â”œâ”€â”€ Upload processing with progress tracking
â”‚   â””â”€â”€ User authentication
â”‚
â””â”€â”€ ğŸ’¾ Data Layer
    â”œâ”€â”€ data/demo_clips/ (input videos)
    â”œâ”€â”€ data/processed/ (annotated videos)
    â””â”€â”€ data/demo_reports/ (AI reports + evidence frames)
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (optional, but recommended for real-time performance)
- Google Gemini API Key (for AI report generation)

### Installation

1. **Clone the repository**
```bash
git clone <your-repo-url>
cd vital-sight
```

2. **Create virtual environment**
```bash
python -m venv myenv

# Windows
myenv\Scripts\activate

# Linux/Mac
source myenv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Download YOLO models** (automatic on first run)
```bash
# Models will be downloaded automatically:
# - yolo11n.pt (object detection)
# - yolo11n-pose.pt (pose estimation)
```

5. **Set up API keys**
```bash
# Windows PowerShell
$env:GEMINI_API_KEY="your-gemini-api-key-here"

# Linux/Mac
export GEMINI_API_KEY="your-gemini-api-key-here"
```

6. **Configure settings** (optional)
```yaml
# Edit config.yaml to customize:
# - Detection thresholds
# - Video input/output settings
# - Runtime parameters
```

---

## ğŸ“– Usage

### ğŸŒ Web Dashboard (Recommended)

**Start the web server:**
```bash
python webapp.py
```

Then open your browser to: `http://localhost:5000`

**Features:**
- ğŸ“º **Grid View**: See all processed videos in a CCTV-style grid
- â¬†ï¸ **Upload**: Process new videos with live detection streaming
- ğŸ“¹ **Webcam**: Real-time detection from connected cameras
- ğŸ” **Authentication**: Secure login (demo: `sohamkagrawal@gmail.com` / `vitalsight`)

### ğŸ“¹ Process Single Video (Command Line)

```bash
python main.py --source path/to/video.mp4 --gemini-key YOUR_API_KEY
```

**Options:**
- `--source`: Video file path or `0` for webcam
- `--no-display`: Run headless (no video window)
- `--config`: Custom config file (default: `config.yaml`)

### ğŸ—‚ï¸ Batch Process Multiple Videos

```bash
python batch_process.py --gemini-key YOUR_API_KEY
```

**Features:**
- Processes all videos in `data/demo_clips/`
- Saves annotated videos to `data/processed/`
- Generates AI reports for all detections
- Optional `--no-clean` flag to preserve existing outputs

**Options:**
- `--input-dir`: Input directory (default: `data/demo_clips`)
- `--exclude`: Folders to skip (default: `['clips']`)
- `--no-gemini`: Skip AI report generation
- `--no-clean`: Don't delete existing outputs before processing

---

## ğŸ¯ Detection Categories & Priorities

| Category | Priority | Response Time | Notification Method |
|----------|----------|---------------|---------------------|
| **Fall** | ğŸŸ¢ LOW | 15-30 minutes | Email + SMS |
| **Crowd/Violence** | ğŸŸ¡ MEDIUM | 5-10 minutes | Email + SMS + Phone Alert |
| **Respiratory Distress** | ğŸŸ  HIGH | 2-5 minutes | **Immediate Phone Call** + SMS |
| **Severe Injury** | ğŸ”´ CRITICAL | < 2 minutes | **Emergency Call + SMS + 911** |
| **Fire** | ğŸ”´ CRITICAL | < 2 minutes | **Emergency Call + Evacuation** |

---

## ğŸ“ Project Structure

```
vital-sight/
â”œâ”€â”€ edge/                          # Core detection modules
â”‚   â”œâ”€â”€ detector_v2.py            # Main detection engine (YOLO + Pose)
â”‚   â”œâ”€â”€ pose.py                   # Pose estimation utilities
â”‚   â””â”€â”€ gemini_reporter.py        # AI report generation
â”‚
â”œâ”€â”€ templates/                     # Web UI templates
â”‚   â”œâ”€â”€ base.html                 # Base layout with navigation
â”‚   â”œâ”€â”€ grid.html                 # CCTV grid view
â”‚   â”œâ”€â”€ detail.html               # Video detail + report view
â”‚   â”œâ”€â”€ upload.html               # Upload with live streaming
â”‚   â”œâ”€â”€ webcam.html               # Webcam interface
â”‚   â””â”€â”€ login.html                # Authentication page
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ demo_clips/               # Input videos
â”‚   â”œâ”€â”€ processed/                # Annotated output videos
â”‚   â””â”€â”€ demo_reports/             # AI-generated reports + frames
â”‚
â”œâ”€â”€ main.py                        # CLI entry point
â”œâ”€â”€ webapp.py                      # Flask web application
â”œâ”€â”€ batch_process.py              # Batch processing script
â”œâ”€â”€ config.yaml                    # Configuration file
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This file
```

---

## ğŸ› ï¸ Configuration

Edit `config.yaml` to customize detection parameters:

```yaml
# Model Configuration
model:
  path: "yolo11n.pt"
  conf: 0.25                      # Detection confidence threshold
  iou: 0.45                       # IoU threshold for NMS

# Pose Estimation
pose:
  enabled: true
  model: "yolo11n-pose.pt"
  max_people: 5                   # Max people to track per frame

# Detection Logic
logic:
  fall:
    threshold: 0.5
    debounce_frames: 10
  fire:
    threshold: 0.3
    hsv_ratio: 0.03
  distress:
    threshold: 0.4
  # ... more categories

# Runtime
runtime:
  show_fps: true
  device: "auto"                  # "cuda", "cpu", or "auto"
```

---

## ğŸ”¬ Technology Stack

- **Deep Learning**: PyTorch, YOLO 11 (Ultralytics)
- **Computer Vision**: OpenCV, MediaPipe, NumPy
- **AI Analysis**: Google Gemini 2.0 Flash (Vision Language Model)
- **Web Framework**: Flask, Tailwind CSS
- **Video Processing**: H.264 codec, MJPEG streaming
- **Authentication**: Flask sessions

---

## ğŸ“Š Performance

- **YOLO 11 Detection**: ~30-60 FPS (GPU) / ~5-10 FPS (CPU)
- **Pose Estimation**: ~20-40 FPS (GPU) / ~3-7 FPS (CPU)
- **AI Report Generation**: 2-5 seconds per incident (async, non-blocking)
- **Video Processing**: Real-time on GPU, 0.5-2x speed on CPU
- **Web Dashboard**: Handles 12+ simultaneous video tiles with autoplay

---

## ğŸ“ Use Cases

- **Healthcare Facilities**: Fall detection in nursing homes and hospitals
- **Industrial Safety**: Monitor for accidents, fires, and safety violations
- **Public Spaces**: Crowd management and violence detection
- **Smart Buildings**: Automated emergency response systems
- **Security Operations**: Real-time threat detection and alerting

---

## ğŸ”® Future Enhancements

- ğŸ“± **Mobile App**: iOS/Android app for remote monitoring
- ğŸ”” **Notification System**: Email/SMS/Voice call integration (Twilio + SendGrid)
- ğŸŒ **Multi-Camera**: Distributed processing across camera networks
- ğŸ“ˆ **Analytics Dashboard**: Historical incident trends and statistics
- ğŸ¤– **Custom Training**: Fine-tune models on domain-specific data
- ğŸ”Š **Audio Analysis**: Sound-based emergency detection (screams, alarms)

---

## ğŸ“ License

[Your License Here]

---

## ğŸ‘¥ Contributors

Built with â¤ï¸ for emergency response and public safety.

---

## ğŸ™ Acknowledgments

- **Ultralytics**: YOLO 11 framework
- **Google**: Gemini Vision Language Model
- **MediaPipe**: Real-time pose estimation
- **OpenCV**: Computer vision foundation

---

## ğŸ“§ Contact

For questions, issues, or collaboration opportunities, please reach out through the repository's issue tracker.

---

**VitalSight** - *Seeing what matters, when it matters most.* ğŸš¨
